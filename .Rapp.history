age.math <- Bchronology(ages=as.numeric(as.vector(age.frame[,2])), ageSds=as.numeric(as.vector(age.frame[,3])), positions=as.numeric(as.vector(age.frame[,1])), positionThickness=rep(0.5, length(age.frame$Sigma)), calCurves=age.frame[,4], burn=2000, predictPositions=as.numeric(as.vector(data.stuff$Depth)))
age.frame
as.numeric(as.vector(age.frame[,2]))
age.math <- Bchronology(ages=as.numeric(as.vector(age.subset[,2])), ageSds=as.numeric(as.vector(age.subset[,3])), positions=as.numeric(as.vector(age.subset[,1])), positionThickness=rep(0.5, length(age.subset $Sigma)), calCurves= age.subset[,4], burn=2000, predictPositions=as.numeric(as.vector(data.stuff$Depth)))
age.results <- predict(age.math, newPositions= data.stuff$Depth, newPositionThicknesses=rep(0.0, length(data.stuff$Depth)))
quartz()
plot(age.math)
head(age.results)
age.results
str(age.results)
str(age.math)
age.results <- predict.BchronologyRun(age.math, newPositions= data.stuff$Depth, newPositionThicknesses=rep(0.0, length(data.stuff$Depth)))
library(Bchron)
age.results <- predict.BchronologyRun(age.math, newPositions= data.stuff$Depth, newPositionThicknesses=rep(0.0, length(data.stuff$Depth)))
age.results <- predict(age.math, newPositions= data.stuff$Depth, newPositionThicknesses=rep(0.0, length(data.stuff$Depth)))
head(age.results)
plot(age.results)
x <- c(500, 1000, 2000, 3000)#
y <- c(50, 100, 100, 100)#
z <- c("intcal13","intcal13","intcal13","intcal13" )#
d <- c(2, 8, 0, 0)#
#
fe <- c(5, 6, 7, 8)#
depth <-c(1, 10, 15, 30)#
#
data.stuff <- data.frame(fe, depth)#
colnames(data.stuff) <- c("Fe", "Depth")#
#
age.frame <- data.frame(d, x, y, z)#
colnames(age.frame) <- c("Depth", "14C Age", "Sigma", "CalCurve")#
#
age.subset <- subset(age.frame, !age.frame$Sigma==0)#
#
      age.math <- Bchronology(ages=as.numeric(as.vector(age.subset[,2])), ageSds=as.numeric(as.vector(age.subset[,3])), positions=as.numeric(as.vector(age.subset[,1])), positionThickness=rep(0.5, length(age.subset $Sigma)), calCurves= age.subset[,4], burn=2000, predictPositions=as.numeric(as.vector(data.stuff$Depth)))#
            age.results <- predict(age.math, newPositions= data.stuff$Depth, newPositionThicknesses=rep(0.0, length(data.stuff$Depth)))
age.subset
x <- c(500, 1000, 2000, 3000)#
y <- c(50, 100, 100, 100)#
z <- c("intcal13","intcal13","intcal13","intcal13" )#
d <- c(2, 8, 0, 0)#
#
fe <- c(5, 6, 7, 8)#
depth <-c(1, 10, 15, 30)#
#
data.stuff <- data.frame(fe, depth)#
colnames(data.stuff) <- c("Fe", "Depth")#
#
age.frame <- data.frame(d, x, y, z)#
colnames(age.frame) <- c("Depth", "14C Age", "Sigma", "CalCurve")#
#
age.subset <- subset(age.frame, !age.frame$Sigma==0)
age.subset
age.frame
x
age.frame <- data.frame(d, x, y, z)
x <- c(500, 1000, 2000, 3000)#
y <- c(50, 100, 100, 100)#
z <- c("intcal13","intcal13","intcal13","intcal13" )#
d <- c(2, 8, 20, 40)#
#
fe <- c(5, 6, 7, 8)#
depth <-c(1, 10, 15, 30)#
#
data.stuff <- data.frame(fe, depth)#
colnames(data.stuff) <- c("Fe", "Depth")#
#
age.frame <- data.frame(d, x, y, z)#
colnames(age.frame) <- c("Depth", "14C Age", "Sigma", "CalCurve")#
#
age.subset <- subset(age.frame, !age.frame$Sigma==0)#
#
      age.math <- Bchronology(ages=as.numeric(as.vector(age.subset[,2])), ageSds=as.numeric(as.vector(age.subset[,3])), positions=as.numeric(as.vector(age.subset[,1])), positionThickness=rep(0.5, length(age.subset $Sigma)), calCurves= age.subset[,4], burn=2000, predictPositions=as.numeric(as.vector(data.stuff$Depth)))#
            age.results <- predict(age.math, newPositions= data.stuff$Depth, newPositionThicknesses=rep(0.0, length(data.stuff$Depth)))
quartz()
plot(age.math)
?plot
head(age.results)
summary(age.results)
fe <- c(5, 6, 7, 8,5, 6, 7, 8,5, 6, 7, 8,5, 6, 7, 8)
length(few)
length(fe)
depth <-seq(1, 30, 2)
length(depth)
fe <- c(5, 6, 7, 8,5, 6, 7, 8,5, 6, 7, 8,5, 6, 7)#
depth <-seq(1, 30, 2)#
#
data.stuff <- data.frame(fe, depth)#
colnames(data.stuff) <- c("Fe", "Depth")
age.results <- predict(age.math, newPositions= data.stuff$Depth, newPositionThicknesses=rep(0.0, length(data.stuff$Depth)))
head(age.results)
median(age.results)
age.vector <- apply(age.results, 1, median)
age.vector
age.vector <- apply(age.results, 2, median)
head(age.vector)
age.vector
age.sd <- apply(age.results, 2, sd)
age.sd
runApp("~/GitHub/Cloudcore")
library(shiny)
runApp("~/GitHub/Cloudcore")
library(shiny)
runApp("~/GitHub/CloudCal")
install.packages("dtplyr")
runApp("~/GitHub/CloudCal")
x <- c(1, 2, 3, 4, 5)
data.frame(x)
as.data.frame(x)
load("~/Downloads/myCalibration-3.quant", verbose=TRUE)
str(Calibration)
ls(Calibration)
test.list <- Calibration$calList
str(test.list)
piece <- "Fe.K.alpha"
piece
test.list[piece]
even.tester <- predict(test.list[piece], as.data.frame(x))
test <- read.csv(file="~/Desktop/Cezanne Face/Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csv")
head(test)
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[.]')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y ]')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y ]', '[)]')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y ]', '')''')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y ]', ')'')[[1]]
)
'
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y ]', ')')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y]', ')')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y]', ')@')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y]', '[)@]')[[1]]
?strsplit
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y]', '[)@]')[[3]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y]', '[)@]')[[2]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', '[X ]', '[Y]', '[)@]')[[1]]
strsplit('Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv', c('[X ]', '[Y]', '[)@]'))[[1]]
name <- "Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csvv"
name
sub('\\D*(\\d{5}).*', '\\1', name)
sub('\\D*(\\d{6}).*', '\\1', name)
sub('\\D*(\\d{5}).*', '\\1', name)
sub('\\D*(\\\d{5}).*', '\\1', name)
sub('\\D*(\\d{5}).*', '\\1', name)
sub('\\D*(\\d{5}).*', '\\2', name)
sub('\\D*(\\d{5}).*', '\\3', name)
sub('\\D*(\\d{5}).*', '\\1', name)
sub('\\D*([X]\\d{5}).*', '\\1', name)
sub('\\D*[X ](\\d{5}).*', '\\1', name)
sub('\\D*(\\d{5}).*', '\\3', name)
sub('\\D*(\\d{6}).*', '\\3', name)
regmatches(name, gregexpr("(?<=@)[a-z]+", tweet,perl=T))
regmatches(name, gregexpr("(?<=@)[a-z]+", name,perl=T))
regmatches(name, gregexpr("(()", name,perl=T))
regmatches(name, gregexpr("()", name,perl=T))
sub('.(_(\\d{5})_.*', '\\1', name)
sub('.'('_(\\d{5})_.*', '\\1', name)
)
sub('.'''('_(\\d{5})_.*', '\\1', name)
sub('.''('_(\\d{5})_.*', '\\1', name)
strapplyc(name, "_(\\d{5})_", simplify = TRUE)
install.packages("gsubfn")
strapplyc(name, "_(\\d{5})_", simplify = TRUE)
library(gsubfn)
strapplyc(name, "_(\\d{5})_", simplify = TRUE)
strapplyc(name, "_(\\d{6})_", simplify = TRUE)
name
ll = unlist(strsplit(name,'()'))
ll
name
strsplit(name, "_")[[1]][3]
strsplit(name, "(X )")[[1]][3]
strsplit(name, "(X ")[[1]][3]
strsplit(name, '(X '[[1]][3]
)
strsplit(name, '(X '[[1]][3])
strsplit(name, '( '[[1]][3])
strsplit(name, '( '[[1]][6])
strsplit(name, '[X ]', '[Y]', '[)@]')[[1]]
strsplit(name, '[ ]', '[Y]', '[)@]')[[1]]
strsplit(name, '[ ]''[)@]')[[1]]
strsplit(name, '[ ]')[[1]]
strsplit(name, '[ ]')
strsplit(name, '[ ]', ')')
strsplit(name, '[ ]', ')@')
strsplit(name, '[ ]', "")@")
)
"
strsplit(name, '[ ]', ")@")
new.test <- strsplit(name, '[ ]')[[1]]
new.test
new.test.x <- new.test[4]
new.test.x
new.test.x <- substr(new.test[6], 1, 6)
new.test.x
new.test.x <- as.numeric(new.test[4])
new.test.x
read_csv_net <- function(filename){#
    filestring <- strsplit(filename, '[ ]')[[1]]#
    x <- as.numeric(filestring[4]#
    y <- as.numeric(substr(filestring[6], 1, 6))#
    ret <- read.csv(file=filename, sep=",", header=FALSE)#
    element <- ret$Element#
    line <- ret$Line#
    net <- ret$net#
    background <- ret$Background#
    x.vector <- rep(x, length(element))#
    y.vector <- rep(y, length(element))#
    data.frame(x, y, element, line, net, background)#
    colnames("X", "Y", "Element", "Line", "Net", "Background")#
    data.frame#
}
read_csv_net <- function(filename){#
    filestring <- strsplit(filename, '[ ]')[[1]]#
    x <- as.numeric(filestring[4]#
    y <- as.numeric(substr(filestring[6], 1, 6))#
    ret <- read.csv(file=filename, sep=",", header=FALSE)#
    element <- ret$Element#
    line <- ret$Line#
    net <- ret$net#
    background <- ret$Background#
    x.vector <- rep(x, length(element))#
    y.vector <- rep(y, length(element))#
    parsed.file <- data.frame(x, y, element, line, net, background)#
    colnames(parsed.file) <- c("X", "Y", "Element", "Line", "Net", "Background")#
    parsed.file#
}
read_csv_net <- function(filename){#
    filestring <- strsplit(filename, '[ ]')[[1]]#
    x <- as.numeric(filestring[4])#
    y <- as.numeric(substr(filestring[6], 1, 6))#
    ret <- read.csv(file=filename, sep=",", header=FALSE)#
    element <- ret$Element#
    line <- ret$Line#
    net <- ret$net#
    background <- ret$Background#
    x.vector <- rep(x, length(element))#
    y.vector <- rep(y, length(element))#
    parsed.file <- data.frame(x, y, element, line, net, background)#
    colnames(parsed.file) <- c("X", "Y", "Element", "Line", "Net", "Background")#
    parsed.file#
}
name
read_csv_net(name)
name <- "~/Dropbox/Documents/Cezanne/Cezanne Face/Cezanne Face_PDHID 81410(X 16.520 Y 12.500)@170617_142335.csv"
name
read_csv_net(name)
filename <- name
filestring <- strsplit(filename, '[ ]')[[1]]
filestring
sub("^[^.]*", "", filename)
sub("^[^X ]*", "", filename)
sub("^[^.]*", "", filename)
strsplit(filename,"\\X ")
strsplit(filename,"\\Y ")
as.numeric(substr(strsplit(filename,"\\X "), 1, 6))
filename
as.numeric(substr(strsplit(filename,"\\X "), 1, 6))
substr(strsplit(filename,"\\X "), 1, 6)
strsplit(filename,"\\X ")
strsplit(filename,"\\X ")[[1]][2]
x <- as.numeric(substr(strsplit(filename,"\\X ")[[1]][2], 1, 6))
x
y <- as.numeric(substr(strsplit(filename,"\\Y ")[[1]][2], 1, 6))
y
read_csv_net <- function(filename){#
    x <- as.numeric(substr(strsplit(filename,"\\X ")[[1]][2], 1, 6))#
    y <- as.numeric(substr(strsplit(filename,"\\Y ")[[1]][2], 1, 6))#
    ret <- read.csv(file=filename, sep=",", header=FALSE)#
    element <- ret$Element#
    line <- ret$Line#
    net <- ret$net#
    background <- ret$Background#
    x.vector <- rep(x, length(element))#
    y.vector <- rep(y, length(element))#
    parsed.file <- data.frame(x, y, element, line, net, background)#
    colnames(parsed.file) <- c("X", "Y", "Element", "Line", "Net", "Background")#
    parsed.file#
}
read_csv_net(filename)
x <- as.numeric(substr(strsplit(filename,"\\X ")[[1]][2], 1, 6))#
    y <- as.numeric(substr(strsplit(filename,"\\Y ")[[1]][2], 1, 6))
x
y
ret <- read.csv(file=filename, sep=",", header=FALSE)
head(ret)
ret <- read.csv(file=filename, sep=",", header=TRUE)
head(ret)
read_csv_net <- function(filename){#
    x <- as.numeric(substr(strsplit(filename,"\\X ")[[1]][2], 1, 6))#
    y <- as.numeric(substr(strsplit(filename,"\\Y ")[[1]][2], 1, 6))#
    ret <- read.csv(file=filename, sep=",", header=TRUE)#
    element <- ret$Element#
    line <- ret$Line#
    net <- ret$net#
    background <- ret$Background#
    x.vector <- rep(x, length(element))#
    y.vector <- rep(y, length(element))#
    parsed.file <- data.frame(x, y, element, line, net, background)#
    colnames(parsed.file) <- c("X", "Y", "Element", "Line", "Net", "Background")#
    parsed.file#
}
read_csv_net(filename)
ret <- read.csv(file=filename, sep=",", header=TRUE)#
    element <- ret$Element#
    line <- ret$Line#
    net <- ret$net#
    background <- ret$Background
head(background)
head(ret)
background <- ret$Backgr.
head(background)
read_csv_net <- function(filename){#
    x <- as.numeric(substr(strsplit(filename,"\\X ")[[1]][2], 1, 6))#
    y <- as.numeric(substr(strsplit(filename,"\\Y ")[[1]][2], 1, 6))#
    ret <- read.csv(file=filename, sep=",", header=TRUE)#
    element <- ret$Element#
    line <- ret$Line#
    net <- ret$net#
    background <- ret$Backgr.#
    x.vector <- rep(x, length(element))#
    y.vector <- rep(y, length(element))#
    parsed.file <- data.frame(x.vector, y.vector, element, line, net, background)#
    colnames(parsed.file) <- c("X", "Y", "Element", "Line", "Net", "Background")#
    parsed.file#
}
read_csv_net(filename)
read_csv_net <- function(filename){#
    x <- as.numeric(substr(strsplit(filename,"\\X ")[[1]][2], 1, 6))#
    y <- as.numeric(substr(strsplit(filename,"\\Y ")[[1]][2], 1, 6))#
    ret <- read.csv(file=filename, sep=",", header=TRUE)#
    element <- ret$Element#
    line <- ret$Line#
    net <- ret$Net#
    background <- ret$Backgr.#
    x.vector <- rep(x, length(element))#
    y.vector <- rep(y, length(element))#
    parsed.file <- data.frame(x.vector, y.vector, element, line, net, background)#
    colnames(parsed.file) <- c("X", "Y", "Element", "Line", "Net", "Background")#
    parsed.file#
}
read_csv_net(filename)
library(shiny)
runApp("~/GitHub/Tracer Map")
install.package("rJava")
install.packages("rJava")
runApp("~/GitHub/Tracer Map")
library(rJAva)
library(rJava)
install.packages("rJava")
library(rJava)
library(shiny)
runApp("~/GitHub/Cezanne")
?scale_fill_alpha
?scale_alpha
runApp("~/GitHub/Cezanne")
?pmax
runApp("~/GitHub/Cezanne")
library(shiny)
runApp("~/GitHub/xrf-app")
library(TTR)#
library(ggplot2)#
library(gridExtra)#
library(scales)#
library(gtable)#
library(wq)
#Tool Types#
big <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Big-Table 1.csv")#
smalls.s <- data.frame(Information, Rb.K12, Sr.K12, Zr.K12, Zn.K12, Fe.K12)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
#Tool Types#
big <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Big-Table 1.csv")#
attach(big)#
smalls.s <- data.frame(Material, Rb.K12, Sr.K12, Zr.K12, Zn.K12, Fe.K12)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
library(pvclust)
#Tool Types#
big <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Big-Table 1.csv")#
attach(big)#
smalls.s <- data.frame(Material, Rb.K12, Sr.K12, Zr.K12, Zn.K12, Fe.K12)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
#Tool Types#
big <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Big-Table 1.csv")#
attach(big)#
smalls.s <- data.frame(Material, Rb.K12, Cu.K12, Zn.K12, Nb.K12)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
#Tool Types#
big <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Big-Table 1.csv")#
attach(big)#
smalls.s <- data.frame(Material, Rb.K12, Cu.K12, Zn.K12, Th.L1, Mn.K12, Nb.K12)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
#Tool Types#
big <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Big-Table 1.csv")#
attach(big)#
smalls.s <- data.frame(Material, Rb.K12, Cu.K12,  Th.L1, Mn.K12, Nb.K12)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
#Tool Types#
big <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Big-Table 1.csv")#
attach(big)#
smalls.s <- data.frame(Material,Rb.K12, Cu.K12, Nb.K12)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
smalls.s <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Small-Table 1.csv")#
attach(small.s)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
smalls.s <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Tiny-Table 1.csv")#
attach(small.s)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)
smalls.s <- read.csv(file="/Users/lee/Google Drive/Liang Bua XRF/Stone 2017/Rock Types/ChertTuff/Medium-Table 1.csv")#
attach(small.s)#
flores.stones.t = setNames(data.frame(t(smalls.s[,-1])), smalls.s[,1])#
fit <- pvclust(flores.stones.t, method.hclust="ward.D",#
   method.dist="euclidean")#
plot(fit) # dendogram with p values#
# add rectangles around groups highly supported by the data#
pvrect(fit, alpha=.95)#
j
library(shiny)
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
runApp("~/GitHub/Cloudcore")
